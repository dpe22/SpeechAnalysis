{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the part 3 of my mini series on Detecting Respiratory Disease. You can check the other parts here:\n",
    "- Part 1: [Creating slices from the audio defined by the .txt files](https://www.kaggle.com/danaelisanicolas/cnn-part-1-create-subslices-for-each-sound)\n",
    "- Part 2: [Splitting to train and test](https://www.kaggle.com/danaelisanicolas/cnn-part-2-split-to-train-and-test)\n",
    "- Part 4: [Creating a model and training spectrogram images](https://www.kaggle.com/danaelisanicolas/cnn-part-4-training-and-modelling-with-vgg16)\n",
    "\n",
    "Now.. To be honest I can't run this fully on Kaggle due to memory constraints. But don't worry, i'll upload the resulting output on the next part of this series. Rather, you can try running this code on your local machine (of course, you have to download all needed input files for this kernel)\n",
    "\n",
    "Without further adeu, let's get into the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  val\r\n"
     ]
    }
   ],
   "source": [
    "!ls '../input/cnn-part-2-split-to-train-and-test/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For creating spectrogram images, I always use the librosa python library. It has a nifty function of creating spectrogram images. You can learn more about it here: https://librosa.github.io/librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import librosa as lb\n",
    "from librosa.display import specshow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to create the directories where we'll store our output. And set the location of the wav files (split into train and val) as input -- generated from part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "os.makedirs('output')\n",
    "os.makedirs('output/train')\n",
    "os.makedirs('output/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_loc = '../input/cnn-part-2-split-to-train-and-test/output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to loop through the directories which are named based on the diagnosis, I need to get all its unique values. We'll name these as categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pId</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>URTI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Asthma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>COPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>URTI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pId diagnosis\n",
       "0  101      URTI\n",
       "1  102   Healthy\n",
       "2  103    Asthma\n",
       "3  104      COPD\n",
       "4  105      URTI"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis_csv = '../input/respiratory-sound-database/respiratory_sound_database/Respiratory_Sound_Database/patient_diagnosis.csv'\n",
    "diagnosis = pd.read_csv(diagnosis_csv, names=['pId', 'diagnosis'])\n",
    "diagnosis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['URTI', 'Healthy', 'Asthma', 'COPD', 'LRTI', 'Bronchiectasis',\n",
       "       'Pneumonia', 'Bronchiolitis'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = diagnosis['diagnosis'].unique()\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create the directories for each category in both train and validation directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in categories:\n",
    "    os.makedirs('output/train/' + cat)\n",
    "    os.makedirs('output/val/' + cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In converting audio to images, we must check whether we're reading an audio file right? I defined is_wav function to check the file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_wav(filename):\n",
    "    '''\n",
    "        Checks if files are .wav files\n",
    "        Utility tool in converting wav to png files\n",
    "    '''\n",
    "    return filename.split('.')[-1] == 'wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function is the core of this kernel. This loads each file in each directory in each split ([split]/[category]/[file]) and converts it to a spectrogram image then saves it on the output directory that should have the same file structure--[split]/[category]/[file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create images using librosa spectogram\n",
    "def convert_to_spec_image(file_loc, filename, category, is_train=False, verbose=False):\n",
    "    ''' \n",
    "        Converts audio file to spec image\n",
    "        Input file includes path\n",
    "        Saves the file to a png image in the save_directory\n",
    "    '''\n",
    "    train_ = 'train/'\n",
    "    val_ = 'val/'\n",
    "    \n",
    "    loc = file_loc + train_ + category + '/' + filename\n",
    "    if is_train == False:\n",
    "        loc = file_loc + val_ + category + '/' + filename\n",
    "\n",
    "    if verbose == True:\n",
    "        print('reading and converting ' + filename + '...')\n",
    "        \n",
    "    y, sr = lb.load(loc)\n",
    "\n",
    "    #Plot signal in\n",
    "    plt.figure(figsize=(10,3))\n",
    "    src_ft = lb.stft(y)\n",
    "    src_db = lb.amplitude_to_db(abs(src_ft))\n",
    "    specshow(src_db, sr=sr, x_axis='time', y_axis='hz')  \n",
    "    plt.ylim(0, 5000)\n",
    "    \n",
    "    save_directory = 'output/'\n",
    "    filename_img = filename.split('.wav')[0]\n",
    "    \n",
    "    save_loc = save_directory + train_ + category + '/' + filename_img + '.png'\n",
    "    if is_train == False:\n",
    "        save_loc = save_directory + val_ + category + '/' + filename_img + '.png'\n",
    "        \n",
    "    plt.savefig(save_loc)\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(filename + ' converted!')\n",
    "        \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start converting! \n",
    "\n",
    "NOTE!!!! I commented out the code that converts the images directly. THe problem is Kaggle can't handle the output that's created. You can however still run this notebook into your machine. Just uncomment the *convert_to_spec_image line and you're good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-10-d0baf2947e8d>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-d0baf2947e8d>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    #convert_to_spec_image(file_loc = files_loc, category=cat, filename=f, is_train=(s == 'train'), verbose=True)\u001b[0m\n\u001b[0m                                                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "split = ['train', 'val']\n",
    "\n",
    "for s in split:\n",
    "    for cat in categories:\n",
    "        print('-' * 100)\n",
    "        print('working on ' + cat + '...')\n",
    "        print('-' * 100)\n",
    "\n",
    "        files = [f for f in listdir(files_loc + s + '/' + cat + '/') if isfile(join(files_loc + s + '/' + cat + '/', f)) and is_wav(f)]\n",
    "        for f in files:\n",
    "            convert_to_spec_image(file_loc = files_loc, category=cat, filename=f, is_train=(s == 'train'), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. We now have our spec images which we can now use for our CNN model. You can get download the output on Part 4 (links above)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
